{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import logging\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vdelavaud\\\\Documents\\\\Projets\\\\MissionTextMining\\\\Données CSV'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir(\"C:\\Users\\vdelavaud\\Documents\")\n",
    "os.chdir(\"Documents\\Projets\\MissionTextMining\\Données CSV\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lecture du fichier \n",
    "train = pd.read_csv('train_E6.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire ressortir les particularités du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vdelavaud\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pour afficher : train[['tweet','nomMethode']].head()\n",
    "\n",
    "# Nombre de mots pour chaque tweet\n",
    "train['word_count'] = train['tweet'].apply(lambda x: len(str(x).split(\" \")))\n",
    "\n",
    "# Nombre de caractères pour chaque tweet\n",
    "train['char_count'] = train['tweet'].str.len() ## this also includes spaces\n",
    "\n",
    "# Taille moyenne des mots\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['tweet'].apply(lambda x: avg_word(x))\n",
    "\n",
    "# Nombre de stopwords\n",
    "stop = stopwords.words('english')\n",
    "train['stopwords'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "# Nombre de caractères spéciaux // Pour le cas du Tweet on prends en comtpe le #\n",
    "train['hastags'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "\n",
    "# Nombre de numérique\n",
    "train['numerics'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "# Nombre de lettre majuscule (Symbole de colère)\n",
    "train['upper'] = train['tweet'].apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>char_count</th>\n",
       "      <th>avg_word</th>\n",
       "      <th>stopwords</th>\n",
       "      <th>hastags</th>\n",
       "      <th>numerics</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>21</td>\n",
       "      <td>102</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>22</td>\n",
       "      <td>122</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>17</td>\n",
       "      <td>86</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  word_count  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...          21   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...          22   \n",
       "2   3      0                                bihday your majesty           5   \n",
       "3   4      0  #model   i love u take with u all the time in ...          17   \n",
       "4   5      0             factsguide: society now    #motivation           8   \n",
       "\n",
       "   char_count  avg_word  stopwords  hastags  numerics  upper  \n",
       "0         102  4.555556         10        1         0      0  \n",
       "1         122  5.315789          5        3         0      0  \n",
       "2          21  5.666667          1        0         0      0  \n",
       "3          86  4.928571          5        1         0      0  \n",
       "4          39  8.000000          1        1         0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nettoyage du fichier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 : Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pour afficher un aperçu, mettre train['tweet'].head()\n",
    "\n",
    "# Tout mettre en minuscule\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "# Supprimer la ponctuation\n",
    "train['tweet'] = train['tweet'].str.replace('[^\\w\\s]','')\n",
    "\n",
    "# Supprimer les stopwords\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "# Recuperer les mots qui reviennent trop fréquemment, les afficher\n",
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[:10]\n",
    "# Les supprimer\n",
    "freq = list(freq.index)\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "\n",
    "# Supprimer les mots rares (Ils sont trop rares pour leur donner du sens, on va donc les supprimer pour obtenir une meilleur compréhension)\n",
    "freq = pd.Series(' '.join(train['tweet']).split()).value_counts()[-10:]\n",
    "freq = list(freq.index)\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "\n",
    "# Correcteur d'orthographe\n",
    "train['tweet'][:5].apply(lambda x: str(TextBlob(x).correct()))\n",
    "\n",
    "# Tokenization\n",
    "TextBlob(train['tweet'][1]).words\n",
    "\n",
    "# Stemming (Racinisation)\n",
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "train['tweet'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "\n",
    "# Lemmatization\n",
    "from textblob import Word\n",
    "train['tweet'] = train['tweet'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    father dysfunctional selfish drag kid dysfunct...\n",
       "1    thanks lyft credit cant use cause dont offer w...\n",
       "2                                       bihday majesty\n",
       "3                              model take urð ðððð ððð\n",
       "4                        factsguide society motivation\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tweet'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\vdelavaud\\\\Documents\\\\Projets\\\\MissionTextMining\\\\Données CSV'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.091342  ,  0.223404  ,  0.58856   , -0.614765  , -0.0838365 ,\n",
       "        0.5387    , -0.43531   ,  0.349125  ,  0.163308  , -0.28223   ,\n",
       "        0.53547   ,  0.52797496,  0.096812  ,  0.2879    , -0.0533385 ,\n",
       "       -0.37232   ,  0.022637  ,  0.574705  , -0.553275  ,  0.385575  ,\n",
       "        0.565335  ,  0.805405  ,  0.2579965 ,  0.0088565 ,  0.1674905 ,\n",
       "        0.25543   , -0.571035  , -0.59926   ,  0.422585  , -0.42896   ,\n",
       "       -0.389065  ,  0.19631   , -0.00933   ,  0.127285  , -0.0487465 ,\n",
       "        0.381435  , -0.22540998,  0.021299  , -0.1827915 , -0.16490501,\n",
       "       -0.47944498, -0.431528  , -0.20091   , -0.55665   , -0.32982   ,\n",
       "       -0.088548  , -0.28038502,  0.219725  ,  0.090537  , -0.67012   ,\n",
       "        0.0883085 , -0.19332   ,  0.0465725 ,  1.160815  ,  0.0691255 ,\n",
       "       -2.47895   , -0.33707   ,  0.083195  ,  1.86185   ,  0.283465  ,\n",
       "       -0.13081   ,  0.927795  , -0.37028   ,  0.1885465 ,  0.66198   ,\n",
       "        0.505175  ,  0.37748498,  0.1322995 , -0.380375  , -0.025135  ,\n",
       "       -0.1636765 , -0.45639   , -0.047815  , -0.87394   ,  0.0264145 ,\n",
       "        0.0117645 , -0.427415  , -0.31048   , -0.317725  , -0.02326   ,\n",
       "        0.525635  ,  0.05760051, -0.69786   , -0.1213325 , -1.2707    ,\n",
       "       -0.225355  , -0.1018815 ,  0.18575001, -0.30943   , -0.211059  ,\n",
       "       -0.279545  , -0.16002001,  0.100371  , -0.05461   , -0.71834505,\n",
       "       -0.392925  ,  0.12075999,  0.61991   ,  0.582145  ,  0.20161   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N-grams (Determiner le sens à partir que la combinaison de n mots)\n",
    "TextBlob(train['tweet'][0]).ngrams(2)\n",
    "# On peut aussi l'utiliser sur 3 mots\n",
    "# TextBlob(train['tweet'][0]).ngrams(3)\n",
    "\n",
    "# Term frequency (TF)\n",
    "# Ratio d'un mot en fonction du tweet\n",
    "# TF = nbr de fois où le terme T apparait dans une ligne / nbr de termes dans la ligne\n",
    "tf1 = (train['tweet'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1\n",
    "\n",
    "\n",
    "# Inverse Document Frequency (IDF)\n",
    "# Un mot ne nous est pas très utile s'il apparaît dans tous les documents\n",
    "#IDF = log(N/n), where, N is the total number of rows and n is the number of rows in which the word was present.\n",
    "for i,word in enumerate(tf1['words']):\n",
    "  tf1.loc[i, 'idf'] = np.log(train.shape[0]/(len(train[train['tweet'].str.contains(word)])))\n",
    "\n",
    "tf1\n",
    "\n",
    "# Frequence des termes TF-IDF (Term Frequency -Inverse Doc Freq)\n",
    "# Calcul de la fréquence d'un terme \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(train['tweet'])\n",
    "\n",
    "train_vect\n",
    "\n",
    "# Bag of words\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(train['tweet'])\n",
    "train_bow\n",
    "    \n",
    "# Sentimental Analysis\n",
    "train['tweet'][:5].apply(lambda x: TextBlob(x).sentiment)\n",
    "train['sentiment'] = train['tweet'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "train[['tweet','sentiment']].head()\n",
    "\n",
    "# Mot (qui vectorise d'autres mots)\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = 'glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "\n",
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)\n",
    "\n",
    "# Prendre les vecteurs mots d'un mot\n",
    "model['go']\n",
    "model['away']\n",
    "\n",
    "(model['go'] + model['away'])/2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons converti la chaîne entière en un vecteur qui peut maintenant être utilisé comme caractéristique dans n'importe quelle technique de modélisation.\n",
    "\n",
    "Il faut maintenant créer le modèle pour analyser les mails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source\n",
    "# https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
